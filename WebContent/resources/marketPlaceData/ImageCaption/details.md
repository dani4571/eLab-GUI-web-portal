# Image Captioning

### About the Application

The image captioning application works by training a CNN and RNN together to translate image features into a human readable text. It can be thought of as an encoder-decoder network where the CNN encodes the image into its features and the RNN decodes them, in the end giving a human readable caption as an output. CNN is first pre-trained for image classification and the last hidden layer of CNN is fed as an input to RNN decoder which is used for language/sentence generation. We show here an example on how the image captioning works and pointers on how to improve the model and integrate it to your own applications.

### Tools

Tensorflow, Python, Natural Language Toolkit (NLTK) and NLTK data

### Recommended Background

General understanding of Deep Learning, Convolutional Neural Networks and Recurrent Neural Networks.

### Test drive this Application

#### Coming Soon..
